{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have built the log-linear model, we are not far away from the feed-forward NN.\n",
    "\n",
    "NN has a more complicated structure than log-linear model. Coming from n-gram, it's a\n",
    "nice path to build our understanding and building blocks.\n",
    "And we will use PyTorch (or TensorFlow 2.0 if you wish) to build this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "We will deal with unknown word with an uniform distribution this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "\n",
    "from math import log\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "\n",
    "from processdata import get_vocabs, load_mapping_from_vocabs, generate_mapping_from_vocabs, tokenize_num, transform_data, writing_seq_idx, START_SYMBOL, STOP_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABS = get_vocabs(\"data/ngram/train.txt\")\n",
    "NKNOWN_SEQUENCE_ID = len(VOCABS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_mapping_from_vocabs('data/nn/vocab_mapping.txt', VOCABS)\n",
    "mapping = load_mapping_from_vocabs('data/nn/vocab_mapping.txt', convert_to_int=False)\n",
    "LEFT_PAD_SYMBOL = int(mapping['<s>'])\n",
    "RIGHT_PAD_SYMBOL = int(mapping['</s>'])\n",
    "\n",
    "for i in [\"train\", \"valid\", \"test\"]:\n",
    "  writing_seq_idx(f\"data/nn/{i}.txt\", transform_data(mapping, f\"data/ngram/{i}.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline\n",
    "We won't apply any optimization over computation. But we will try to vectorize\n",
    "our computation. To see more, checkout SIMD. Deep learning framework can also utilize\n",
    "many new devices.\n",
    "\n",
    "Our previous computation happens every sequence (two words for tri-gram).\n",
    "And optimization steps cost a lot. What if we build a mini-batches?\n",
    "\n",
    "Here, we don't use PyTorch's data loader. We build things that you can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_to_indexes(\n",
    "    sequence,\n",
    "    n\n",
    "):\n",
    "  return chain((LEFT_PAD_SYMBOL,) * (n - 1), iter(sequence), (RIGHT_PAD_SYMBOL,) * (n - 1))\n",
    "\n",
    "def dataloader(filename, batch_size, n):\n",
    "  def gen_token(l):\n",
    "    for token in tokenize_num(l):\n",
    "      try:\n",
    "        token = int(token)\n",
    "      except:\n",
    "        token = UNKNOWN_SEQUENCE_ID\n",
    "      yield token\n",
    "  \n",
    "  def gen(n):\n",
    "    with open(filename, 'r') as f:\n",
    "      for l in f:\n",
    "        for s in translate_sentence_to_indexes(gen_token(l), n):\n",
    "          yield s\n",
    "\n",
    "  def ngram(sequence, n):\n",
    "    history = []\n",
    "    while n > 1:\n",
    "      try:\n",
    "        next_item = next(sequence)\n",
    "      except StopIteration:\n",
    "        # no more data, terminate the generator\n",
    "        return\n",
    "      history.append(next_item)\n",
    "      n -= 1\n",
    "\n",
    "    for item in sequence:\n",
    "      history.append(item)\n",
    "      yield np.array(history, dtype=np.int64)\n",
    "      del history[0]\n",
    "\n",
    "  return ngram(ngram(gen(n), n), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15567, 15567, 20957],\n",
       "       [15567, 20957, 39763],\n",
       "       [20957, 39763, 28909],\n",
       "       [39763, 28909,  7625],\n",
       "       [28909,  7625, 41481],\n",
       "       [ 7625, 41481,    96],\n",
       "       [41481,    96, 36480],\n",
       "       [   96, 36480,  5623],\n",
       "       [36480,  5623, 32051],\n",
       "       [ 5623, 32051, 30453]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataloader('data/nn/train.txt', 10, 3)) # for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15567, 20957],\n",
       "       [20957, 39763],\n",
       "       [39763, 28909],\n",
       "       [28909,  7625],\n",
       "       [ 7625, 41481],\n",
       "       [41481,    96],\n",
       "       [   96, 36480],\n",
       "       [36480,  5623],\n",
       "       [ 5623, 32051],\n",
       "       [32051, 30453]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataloader('data/nn/train.txt', 10, 2)) # to test trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NN\n",
    "\n",
    "Now we are in a good sport. Let's build a NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tri-gram can be expressed like this:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \\boldsymbol{m} &=\\operatorname{concat}\\left(M_{, e_{t-2}}, M_{, e_{t-1}}\\right) \\\\ \\boldsymbol{h} &=\\tanh \\left(W_{m h} \\boldsymbol{m}+\\boldsymbol{b}_{h}\\right) \\\\ \\boldsymbol{s} &=W_{h s} \\boldsymbol{h}+\\boldsymbol{b}_{s} \\\\ \\boldsymbol{p} &=\\operatorname{softmax}(\\boldsymbol{s}) \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "    self.embedding = torch.nn.Embedding(len(VOCABS), len(VOCABS))\n",
    "    hidden_size = int(0.3*len(VOCABS)) # random\n",
    "    self.first = torch.nn.Linear(2*len(VOCABS), hidden_size) # tri-gram here\n",
    "    self.tanh = torch.nn.Tanh()\n",
    "    self.hidden = torch.nn.Linear(hidden_size, len(VOCABS))\n",
    "    self.softmax = torch.nn.LogSoftmax()\n",
    "    self.loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.embedding(x).reshape(x.shape[0], -1)\n",
    "    x = self.tanh(self.first(x))\n",
    "    x = self.hidden(x)\n",
    "    p = self.softmax(x)\n",
    "    return p\n",
    "  \n",
    "  def loss(self, p, target):\n",
    "    return self.loss_fn(p, target)\n",
    "\n",
    "def train(dataloader, epoch):\n",
    "  data = iter(dataloader)\n",
    "  model = Model()\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "  for i in range(epoch):\n",
    "    loss_val = 0.0\n",
    "    for batch in data:\n",
    "      batch = torch.from_numpy(batch)\n",
    "      target = batch[:,2]\n",
    "      x = batch[:,:2]\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      result = model.forward(x)\n",
    "      output = model.loss(result, target)\n",
    "      loss_val += output.item()\n",
    "      output.backward()\n",
    "      optimizer.step()\n",
    "    print(f\"loss: {loss_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dataloader('data/nn/train.txt', 100, 3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
